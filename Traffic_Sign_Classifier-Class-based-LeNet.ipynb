{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Udacity: Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "## Project: Build a Traffic Sign Recognition Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 0: Load The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "# Visualizations will be shown in the notebook.\n",
    "%matplotlib inline\n",
    "\n",
    "# Load pickled data\n",
    "training_file = './traffic-signs-data/train.p'\n",
    "validation_file= './traffic-signs-data/valid.p'\n",
    "testing_file = './traffic-signs-data/test.p'\n",
    "train_dict = pickle.load(open(training_file, mode='rb') )\n",
    "valid_dict = pickle.load(open(validation_file, mode='rb'))\n",
    "test_dict  = pickle.load(open(testing_file, mode='rb'))\n",
    "\n",
    "X_train, y_train = train_dict['features'], train_dict['labels']\n",
    "X_valid, y_valid = valid_dict['features'], valid_dict['labels']\n",
    "X_test, y_test   = test_dict['features'], test_dict['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Step 1: Data augmentation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image processing library functions\n",
    "from img_lib import list_images, rotate_image, translate_image, shear_image \n",
    "from img_lib import change_brightness_image, motion_blur_image\n",
    "\n",
    "def random_transform_image(image):    \n",
    "    if np.random.randint(2) == 0:\n",
    "        return image\n",
    "    \n",
    "    transformation_library = ['rotation','translation','shear','brightness','blur']    \n",
    "    transformation_id = transformation_library[np.random.randint(len(transformation_library))]\n",
    "    \n",
    "    if transformation_id == 'rotation':\n",
    "        image = rotate_image(image)\n",
    "        \n",
    "    if transformation_id == 'translation':\n",
    "        image = translate_image(image)\n",
    "    \n",
    "    if transformation_id == 'shear':\n",
    "        image = shear_image(image)\n",
    "\n",
    "    if transformation_id == 'brightness':\n",
    "        image = change_brightness_image(image)\n",
    "        \n",
    "    if transformation_id == 'blur':\n",
    "        image = motion_blur_image(image)\n",
    "        \n",
    "    if transformation_id == 'grayscale':\n",
    "        image = gray_scale_image(image)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def generator_data(X_data):\n",
    "    return np.array([random_transform_image(image) for image in X_data]).reshape(X_data.shape[0], 32,32,-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sameerp/Documents/Udacity/SDCND/Term-1/CarND-Traffic-Sign-Classifier-Project/class_lenet.py:54: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "0.9086167800453515\n"
     ]
    }
   ],
   "source": [
    "from class_lenet import LeNet\n",
    "\n",
    "n_classes = 43\n",
    "model_fname = './OptimizedModel'\n",
    "model = LeNet(n_classes)\n",
    "model.compile(optimizer = tf.train.AdamOptimizer(learning_rate = 2e-3), activation_function = 'relu')\n",
    "model.fit(x = X_train, y = y_train, batch_size = 64, \n",
    "          epochs = 2, \n",
    "          generator = generator_data,\n",
    "          dropout_probabilities = {'keep_fc_3': 0.5, 'keep_fc_4': 0.5},\n",
    "          validation_data = {'features': X_valid, 'labels': y_valid},\n",
    "          save_trained_weights = model_fname, \n",
    "          verbose = False\n",
    "         )\n",
    "results = model.get_results_per_epoch()\n",
    "training_loss_per_epoch = results['training_loss']\n",
    "training_accuracy_per_epoch = results['training_accuracy']\n",
    "validation_accuracy_per_epoch = results['validation_accuracy']\n",
    "validation_loss_per_epoch = results['validation_loss']\n",
    "print(np.max(validation_accuracy_per_epoch))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model on test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./OptimizedModel\n",
      "validation errors = 204\n",
      "validation accuracy = 0.9537414965986395\n",
      "test errors = 726\n",
      "test accuracy = 0.9425178147268408\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,  model_fname)\n",
    "    valid_results  = model.evaluate(model.preprocess_data(X_valid), y_valid)    \n",
    "    print(\"validation errors = {}\".format(len(valid_results[\"error_list\"])))\n",
    "    print(\"validation accuracy = {}\".format(valid_results[\"accuracy\"]))\n",
    "    test_results    = model.evaluate(model.preprocess_data(X_test), y_test)\n",
    "    print(\"test errors = {}\".format(len(test_results[\"error_list\"])))\n",
    "    print(\"test accuracy = {}\".format(test_results[\"accuracy\"]))\n",
    "    \n",
    "    test_errors_rnd_idx = np.random.randint(len(test_results[\"error_list\"]),size = 30)\n",
    "    #list_images(valid_dict['features'][valid_results[\"error_list\"]])\n",
    "    #list_images(test_dict['features'][test_errors_rnd_idx])\n",
    "    #plt.hist(test_dict['labels'][test_results[\"error_list\"]])\n",
    "    #plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
